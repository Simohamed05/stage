import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import io
import numpy as np
from statsmodels.tsa.arima.model import ARIMA
from scipy import stats
import warnings
from docx import Document
from docx.shared import Inches, Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH
import plotly.io as pio
import uuid

# Suppress warnings for cleaner output ğŸš¨
warnings.filterwarnings("ignore")

# Streamlit page configuration ğŸŒŸ
st.set_page_config(page_title="Tableau de Bord Consommation ğŸŒ", layout="wide", initial_sidebar_state="expanded")

# Custom dark theme CSS ğŸ¨
st.markdown("""
    <style>
    .main { background-color: #1e1e1e; color: #ffffff; }
    h1, h2, h3 { color: #ffffff; }
    .stDataFrame { background-color: #2d2d2d; color: #ffffff; }
    .stMetric { background-color: #2d2d2d; padding: 10px; border-radius: 5px; }
    .stButton>button { background-color: #4CAF50; color: white; border-radius: 5px; }
    .stSelectbox, .stSlider { margin-bottom: 10px; }
    .stExpander { background-color: #2d2d2d; border-radius: 5px; }
    </style>
""", unsafe_allow_html=True)

# Utility functions ğŸ› ï¸
def abbreviate_number(num):
    if pd.isna(num) or num == 0:
        return "0"
    if num >= 1_000_000:
        return f"{num / 1_000_000:.1f}M"
    if num >= 1_000:
        return f"{num / 1_000:.1f}K"
    return f"{num:.2f}"

def convert_df_to_csv(df):
    return df.to_csv(index=False).encode('utf-8')

def save_plotly_fig_as_image(fig, filename):
    pio.write_image(fig, filename, format="png")
    return filename

def sanitize_text(text):
    if pd.isna(text):
        return "N/A"
    return str(text).replace("\n", " ").replace("\r", " ").strip()

# Function to generate Word report ğŸ“
def generate_word_document(selected_org, selected_cat, date_range, viz_data, filtered_data, total_quantity, total_cost, unique_articles, top_article):
    doc = Document()
    
    # Title
    title = doc.add_heading("Documentation du Tableau de Bord de Consommation ğŸ“Šâœ¨", level=1)
    title.alignment = WD_ALIGN_PARAGRAPH.CENTER
    title.runs[0].font.size = Pt(16)

    # Introduction
    doc.add_heading("Introduction ğŸŒŸ", level=2)
    intro_text = (
        f"Ce document dÃ©crit le **Tableau de Bord de Consommation**, une application interactive dÃ©veloppÃ©e pour analyser les donnÃ©es de consommation issues du fichier `consommation.xlsx`. "
        f"Les analyses sont filtrÃ©es pour l'organisation **{selected_org if selected_org != 'Tous' else 'toutes les organisations'}**, "
        f"la catÃ©gorie **{selected_cat if selected_cat != 'Tous' else 'toutes les catÃ©gories'}**, et la pÃ©riode du **{date_range[0]} au {date_range[1]}**. "
        f"ConÃ§u pour les utilisateurs de tous niveaux, ce tableau de bord fournit des visualisations interactives, des analyses avancÃ©es, et des recommandations exploitables pour optimiser la gestion de la consommation. ğŸš€\n\n"
        f"Dans le contexte de la gestion de la consommation, les entreprises font face Ã  des dÃ©fis tels que la maÃ®trise des coÃ»ts, lâ€™optimisation des stocks, et la dÃ©tection des anomalies. "
        f"Ce tableau de bord rÃ©pond Ã  ces enjeux en offrant une vue dâ€™ensemble des tendances de consommation, des catÃ©gories dominantes, et des articles les plus consommÃ©s, "
        f"tout en identifiant les pics inhabituels pour une meilleure planification. ğŸŒ"
    )
    doc.add_paragraph(intro_text)

    # Data Processing
    doc.add_heading("Traitement des DonnÃ©es ğŸ—‚ï¸", level=2)
    doc.add_paragraph(
        "Le tableau de bord commence par charger et nettoyer les donnÃ©es du fichier Excel `consommation.xlsx`. "
        "Cette Ã©tape garantit la fiabilitÃ© des analyses en corrigeant les erreurs, valeurs manquantes, et formats incohÃ©rents. ğŸ§¹"
    )
    data_steps = [
        ("Chargement des DonnÃ©es ğŸ“¥", 
         "Le fichier Excel est lu avec Pandas. Les colonnes incluent : `Date` (date de consommation), `Org_Log` (organisation), `Desc_Cat` (catÃ©gorie), "
         "`Article` (nom de lâ€™article), `Qte` (quantitÃ© consommÃ©e), et `Montant` (coÃ»t total). Les lignes vides sont supprimÃ©es."),
        ("Nettoyage des DonnÃ©es ğŸ§¼", 
         "La colonne `Date` est convertie en format `datetime` (format attendu : `YYYYMMDD`). Les colonnes numÃ©riques (`Qte`, `Montant`) sont converties en nombres, "
         "avec `0` pour les valeurs manquantes. Les colonnes `Org_Log`, `Desc_Cat`, et `Article` sont converties en chaÃ®nes de caractÃ¨res, avec `'Inconnu'` pour les valeurs manquantes."),
        ("Calculs DÃ©rivÃ©s ğŸ§®", 
         "Le coÃ»t moyen par unitÃ© est calculÃ© comme `Montant / Qte` (lorsque `Qte > 0`). Les donnÃ©es sont agrÃ©gÃ©es par article pour Ã©viter les doublons dans certaines visualisations.")
    ]
    for title, desc in data_steps:
        doc.add_heading(title, level=3)
        doc.add_paragraph(desc)

    # Global Metrics
    doc.add_heading("MÃ©triques Globales ğŸ“", level=2)
    doc.add_paragraph(f"QuantitÃ© Totale: {abbreviate_number(total_quantity)} unitÃ©s ğŸ›’")
    doc.add_paragraph(f"CoÃ»t Total: {abbreviate_number(total_cost)} MAD ğŸ’¸")
    doc.add_paragraph(f"CoÃ»t Moyen par Jour: {abbreviate_number(total_cost / filtered_data['Date'].nunique())} MAD/j ğŸ“…")
    doc.add_paragraph(f"Articles Uniques: {unique_articles} ğŸ·ï¸")
    if top_article is not None:
        doc.add_paragraph(f"Article le Plus CoÃ»teux: {sanitize_text(top_article['Article'])} ({abbreviate_number(top_article['Montant'])} MAD) ğŸ’°")

    # Visualizations
    doc.add_heading("Visualisations ğŸ“ˆğŸš€", level=2)
    doc.add_paragraph(
        "Les visualisations interactives, rÃ©alisÃ©es avec Plotly et un thÃ¨me sombre, permettent dâ€™explorer les donnÃ©es de consommation. "
        "Chaque graphique rÃ©pond Ã  des questions spÃ©cifiques, comme lâ€™identification des catÃ©gories coÃ»teuses ou des tendances temporelles. ğŸ¨"
    )
    visualizations = [
        ("Tendance Temporelle ğŸ“…", 
         "Une courbe montre lâ€™Ã©volution de la quantitÃ© ou du coÃ»t total par jour, avec une option de lissage (moyenne mobile)."),
        ("RÃ©partition par CatÃ©gorie ğŸ¥§", 
         "Un graphique en donut affiche la part des coÃ»ts ou quantitÃ©s par catÃ©gorie, avec les pourcentages et montants exacts au survol."),
        ("Top Articles ğŸ†", 
         "Un histogramme prÃ©sente les 5 articles les plus consommÃ©s par quantitÃ© ou coÃ»t, avec des Ã©tiquettes claires."),
        ("RÃ©partition des QuantitÃ©s par Organisation ğŸ“Š", 
         "Un graphique en boÃ®te montre la variabilitÃ© des quantitÃ©s consommÃ©es par organisation, mettant en Ã©vidence les mÃ©dianes et valeurs aberrantes.")
    ]
    for title, desc in visualizations:
        doc.add_heading(title, level=3)
        doc.add_paragraph(desc)

    # Embed Visualizations
    doc.add_heading("Visualisations Graphiques ğŸ–¼ï¸", level=2)
    
    # 1. Tendance Temporelle
    doc.add_heading("Tendance Temporelle ğŸ“…", level=3)
    fig_trend = px.line(
        viz_data['trend_data'],
        x='Date',
        y='Valeur',
        color='MÃ©trique',
        title=f"Tendance de {viz_data['trend_metric']} au Fil du Temps",
        labels={'Valeur': viz_data['trend_metric']},
        template='plotly_dark',
        hover_data={'Valeur': ':,.2f'}
    )
    fig_trend.update_layout(font=dict(size=12), xaxis_tickangle=45)
    trend_img = "trend.png"
    save_plotly_fig_as_image(fig_trend, trend_img)
    doc.add_picture(trend_img, width=Inches(6))

    # 2. RÃ©partition par CatÃ©gorie
    doc.add_heading("RÃ©partition par CatÃ©gorie ğŸ¥§", level=3)
    if not viz_data['cat_data'].empty and isinstance(viz_data['cat_data'], pd.DataFrame) and 'Desc_Cat' in viz_data['cat_data'].columns and 'Valeur' in viz_data['cat_data'].columns:
        fig_cat = px.pie(
            viz_data['cat_data'],
            names='Desc_Cat',
            values='Valeur',
            title=f"RÃ©partition des {viz_data['cat_metric']} par CatÃ©gorie",
            template='plotly_dark',
            color_discrete_sequence=px.colors.qualitative.Bold,
            hover_data={'Valeur': ':,.2f'}
        )
        fig_cat.update_traces(textinfo="percent+label")
        cat_img = "category.png"
        save_plotly_fig_as_image(fig_cat, cat_img)
        doc.add_picture(cat_img, width=Inches(6))
    else:
        doc.add_paragraph("Aucune donnÃ©e disponible pour la rÃ©partition par catÃ©gorie. ğŸ˜¢")

    # 3. Top Articles
    doc.add_heading("Top Articles ğŸ†", level=3)
    fig_top = px.bar(
        viz_data['top_articles'],
        x='Article',
        y='Valeur',
        title=f"Top 5 Articles par {viz_data['art_metric']}",
        labels={'Valeur': viz_data['art_metric']},
        template='plotly_dark',
        hover_data={'Valeur': ':,.2f'},
        text_auto=True
    )
    fig_top.update_layout(font=dict(size=12), xaxis_tickangle=45)
    top_img = "top_articles.png"
    save_plotly_fig_as_image(fig_top, top_img)
    doc.add_picture(top_img, width=Inches(6))

    # 4. RÃ©partition des QuantitÃ©s par Organisation
    doc.add_heading("RÃ©partition des QuantitÃ©s par Organisation ğŸ“Š", level=3)
    fig_box = px.box(
        viz_data['box_data'],
        x='Org_Log',
        y='Qte',
        title="RÃ©partition des QuantitÃ©s par Organisation",
        template='plotly_dark',
        hover_data={'Qte': ':,.2f'}
    )
    fig_box.update_layout(font=dict(size=12), xaxis_tickangle=45, showlegend=False)
    box_img = "box.png"
    save_plotly_fig_as_image(fig_box, box_img)
    doc.add_picture(box_img, width=Inches(6))

    # Advanced Analyses
    doc.add_heading("Analyses AvancÃ©es ğŸ”ğŸš€", level=2)
    doc.add_paragraph(
        "Des analyses statistiques et prÃ©dictives fournissent des insights approfondis pour anticiper la consommation et dÃ©tecter les anomalies. ğŸ§ "
    )

    # Demand Forecasting
    doc.add_heading("PrÃ©vision de la Consommation ğŸ“ˆ", level=3)
    doc.add_paragraph(
        "PrÃ©vision de la consommation pour les 5 articles les plus consommÃ©s sur les 6 prochains mois Ã  lâ€™aide du modÃ¨le ARIMA. ğŸ”®"
    )
    if not viz_data['forecast_data'].empty:
        fig_forecast = px.line(
            viz_data['forecast_data'],
            x='Index',
            y='QuantitÃ©',
            color='Article',
            line_dash='Type',
            title='PrÃ©vision de la Consommation pour les Top Articles',
            labels={'Index': 'PÃ©riode'},
            template='plotly_dark',
            hover_data={'QuantitÃ©': ':,.2f'}
        )
        fig_forecast.update_layout(font=dict(size=12), xaxis_tickangle=45)
        forecast_img = "forecast.png"
        save_plotly_fig_as_image(fig_forecast, forecast_img)
        doc.add_picture(forecast_img, width=Inches(6))
    else:
        doc.add_paragraph("Aucune donnÃ©e disponible pour la prÃ©vision de la consommation. ğŸ˜¢")

    # Anomaly Detection
    doc.add_heading("DÃ©tection des Anomalies âš ï¸", level=3)
    doc.add_paragraph(
        "Identification des consommations inhabituelles par catÃ©gorie Ã  lâ€™aide des scores Z (Z > 3 ou < -3). ğŸ•µï¸â€â™‚ï¸"
    )
    if not viz_data['anomaly_data'].empty:
        table = doc.add_table(rows=1, cols=len(viz_data['anomaly_data'].columns))
        hdr_cells = table.rows[0].cells
        for i, col in enumerate(viz_data['anomaly_data'].columns):
            hdr_cells[i].text = col
        for _, row in viz_data['anomaly_data'].head(10).iterrows():
            row_cells = table.add_row().cells
            for col_idx, value in enumerate(row):
                row_cells[col_idx].text = sanitize_text(value)
    else:
        doc.add_paragraph("Aucune anomalie dÃ©tectÃ©e. âœ…")

    # Save document to buffer
    buffer = io.BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

# Load and process data ğŸ“‚
@st.cache_data
def load_and_process_data():
    try:
        df = pd.read_excel("consommation.xlsx", na_values=['', 'NA', 'NaT'])
    except Exception as e:
        st.error(f"Erreur lors du chargement du fichier Excel : {e} ğŸ˜¢")
        return pd.DataFrame()
    
    # Clean data ğŸ§¹
    df = df.dropna(how='all')
    df["Date"] = pd.to_datetime(df["Date"], format="%Y%m%d", errors='coerce')
    df["Qte"] = pd.to_numeric(df["Qte"], errors='coerce').fillna(0)
    df["Montant"] = pd.to_numeric(df["Montant"], errors='coerce').fillna(0)
    df["Org_Log"] = df["Org_Log"].astype(str).fillna('Inconnu')
    df["Desc_Cat"] = df["Desc_Cat"].astype(str).fillna('Inconnu')
    df["Article"] = df["Article"].astype(str).fillna('Inconnu')
    df["unit_cost"] = df.apply(lambda row: row["Montant"] / row["Qte"] if row["Qte"] > 0 else 0, axis=1)
    
    # Aggregated data for visualizations ğŸ“Š
    df_aggregated = df.groupby("Article").agg({
        "Qte": "sum",
        "Montant": "sum",
        "Org_Log": "first",
        "Desc_Cat": "first",
        "Date": "first"
    }).reset_index()
    df_aggregated["unit_cost"] = df_aggregated.apply(
        lambda row: row["Montant"] / row["Qte"] if row["Qte"] > 0 else 0, axis=1
    )
    
    return df, df_aggregated

# Process data for visualizations and analyses ğŸ“ˆ
@st.cache_data
def process_visualization_data(df, df_aggregated, selected_org, selected_cat, date_range, trend_metric, cat_metric, art_metric):
    filtered_df = df.copy()
    filtered_df_aggregated = df_aggregated.copy()
    
    # Apply filters ğŸ”
    filtered_df = filtered_df[(filtered_df["Date"].dt.date >= date_range[0]) & (filtered_df["Date"].dt.date <= date_range[1])]
    if selected_org != "Tous":
        filtered_df = filtered_df[filtered_df["Org_Log"] == selected_org]
        filtered_df_aggregated = filtered_df_aggregated[filtered_df_aggregated["Org_Log"] == selected_org]
    if selected_cat != "Tous":
        filtered_df = filtered_df[filtered_df["Desc_Cat"] == selected_cat]
        filtered_df_aggregated = filtered_df_aggregated[filtered_df_aggregated["Desc_Cat"] == selected_cat]
    
    # Visualization data ğŸ“Š
    trend_data = filtered_df.groupby(filtered_df["Date"].dt.date)[trend_metric].sum().reset_index()
    trend_data.columns = ['Date', 'Valeur']
    trend_data['MÃ©trique'] = trend_metric
    
    # Handle category data with robust validation ğŸ›¡ï¸
    if not filtered_df.empty and cat_metric in filtered_df.columns and 'Desc_Cat' in filtered_df.columns:
        try:
            # Perform groupby and ensure DataFrame output
            cat_data = filtered_df.groupby("Desc_Cat")[cat_metric].sum().reset_index()
            # Rename columns explicitly
            cat_data.columns = ['Desc_Cat', 'Valeur']
            # Verify that cat_data is a DataFrame
            if not isinstance(cat_data, pd.DataFrame):
                cat_data = pd.DataFrame({'Desc_Cat': [], 'Valeur': []})
            elif cat_data.empty:
                cat_data = pd.DataFrame(columns=['Desc_Cat', 'Valeur'])
        except Exception as e:
            st.warning(f"Erreur lors du traitement des donnÃ©es de catÃ©gorie : {e} ğŸ˜¢")
            cat_data = pd.DataFrame(columns=['Desc_Cat', 'Valeur'])
    else:
        cat_data = pd.DataFrame(columns=['Desc_Cat', 'Valeur'])
    
    top_articles = filtered_df_aggregated.nlargest(5, art_metric)[["Article", art_metric]]
    top_articles.columns = ['Article', 'Valeur']
    box_data = filtered_df[["Org_Log", "Qte"]]
    
    # Forecasting ğŸ”®
    forecast_data = []
    forecast_recommendations = []
    top_items = filtered_df_aggregated.nlargest(5, "Qte")["Article"].tolist()
    for item in top_items:
        item_data = filtered_df[filtered_df["Article"] == item][["Date", "Qte"]].dropna(subset=['Qte'])
        if len(item_data) >= 3:
            item_data = item_data.groupby(item_data["Date"].dt.to_period('M'))["Qte"].sum().reset_index()
            item_data["Date"] = item_data["Date"].dt.to_timestamp()
            quantities = item_data["Qte"].values
            indices = item_data["Date"]
            forecast_steps = pd.date_range(start=indices.max() + pd.offsets.MonthBegin(1), periods=6, freq='M')
            try:
                model = ARIMA(quantities, order=(1, 1, 1))
                fit = model.fit()
                forecast = fit.forecast(steps=6)
                forecast = np.clip(forecast, 0, None)
                historical_df = pd.DataFrame({
                    'Index': indices,
                    'QuantitÃ©': quantities,
                    'Article': item,
                    'Type': 'Historique'
                })
                forecast_df = pd.DataFrame({
                    'Index': forecast_steps,
                    'QuantitÃ©': forecast,
                    'Article': item,
                    'Type': 'PrÃ©vision'
                })
                forecast_data.append(pd.concat([historical_df, forecast_df]))
                total_forecast = forecast.sum()
                forecast_recommendations.append(f"Stockez environ {int(total_forecast * 1.1)} unitÃ©s de {item} pour couvrir la consommation prÃ©vue sur 6 mois (10% de marge). ğŸ“¦")
            except:
                pass
    forecast_data = pd.concat(forecast_data) if forecast_data else pd.DataFrame()
    
    # Anomaly detection ğŸ•µï¸â€â™‚ï¸
    anomalies = []
    for cat in filtered_df["Desc_Cat"].unique():
        cat_data = filtered_df[filtered_df["Desc_Cat"] == cat]["Montant"]
        if len(cat_data) > 10 and cat_data.var() > 0:
            z_scores = stats.zscore(cat_data)
            anomaly_indices = cat_data.index[abs(z_scores) > 3]
            for idx in anomaly_indices:
                anomalies.append({
                    'Article': filtered_df.loc[idx, 'Article'],
                    'Desc_Cat': cat,
                    'Montant': filtered_df.loc[idx, 'Montant']
                })
    anomaly_data = pd.DataFrame(anomalies) if anomalies else pd.DataFrame(columns=['Article', 'Desc_Cat', 'Montant'])
    
    return {
        'trend_data': trend_data,
        'trend_metric': trend_metric,
        'cat_data': cat_data,
        'cat_metric': cat_metric,
        'top_articles': top_articles,
        'art_metric': art_metric,
        'box_data': box_data,
        'forecast_data': forecast_data,
        'forecast_recommendations': forecast_recommendations,
        'anomaly_data': anomaly_data
    }

# Load data ğŸ“‚
df, df_aggregated = load_and_process_data()
if df.empty:
    st.error("Impossible de charger les donnÃ©es. VÃ©rifiez le fichier 'consommation.xlsx'. âš ï¸ğŸ˜¢")
    st.stop()

# Sidebar filters ğŸ”
st.sidebar.header("ğŸ” Filtres & ParamÃ¨tres ğŸ› ï¸")
org_options = ["Tous"] + sorted(df["Org_Log"].unique().tolist())
selected_org = st.sidebar.selectbox("Organisation ğŸ¢", org_options)
cat_options = ["Tous"] + sorted(df["Desc_Cat"].unique().tolist())
selected_cat = st.sidebar.selectbox("CatÃ©gorie ğŸ—‚ï¸", cat_options)
date_range = st.sidebar.date_input("PÃ©riode ğŸ“…", 
                                  [df["Date"].min().date(), df["Date"].max().date()],
                                  min_value=df["Date"].min().date(),
                                  max_value=df["Date"].max().date())

# Advanced options âš™ï¸
with st.sidebar.expander("âš™ï¸ Options avancÃ©es ğŸ”§"):
    trend_metric = st.radio("MÃ©trique Tendance ğŸ“ˆ", ["Qte", "Montant"])
    cat_metric = st.radio("MÃ©trique CatÃ©gorie ğŸ¥§", ["Qte", "Montant"], key="cat_met")
    art_metric = st.radio("MÃ©trique Article ğŸ†", ["Qte", "Montant"], key="art_met")
    smoothing = st.slider("Lissage (jours) â³", 0, 30, 7)

# Process visualization data ğŸ“Š
viz_data = process_visualization_data(df, df_aggregated, selected_org, selected_cat, date_range, trend_metric, cat_metric, art_metric)

# Dashboard title ğŸŒŸ
st.title("ğŸ“Š Tableau de Bord de Consommation ğŸŒ")
st.write("Explorez les donnÃ©es de consommation avec des visualisations interactives et des analyses avancÃ©es pour optimiser la gestion des ressources. ğŸš€âœ¨")

# KPI Metrics ğŸ“
st.header("ğŸ“Œ MÃ©triques Globales ğŸŒŸ")
total_quantity = df_aggregated["Qte"].sum()
total_cost = df_aggregated["Montant"].sum()
unique_articles = df_aggregated["Article"].nunique()
top_article = df_aggregated.loc[df_aggregated["Montant"].idxmax()] if not df_aggregated.empty else None

col1, col2, col3, col4 = st.columns(4)
col1.metric("QuantitÃ© Totale ğŸ›’", f"{abbreviate_number(total_quantity)} unitÃ©s")
col2.metric("CoÃ»t Total ğŸ’¸", f"{abbreviate_number(total_cost)} MAD")
col3.metric("CoÃ»t Moyen par Jour ğŸ“…", f"{abbreviate_number(total_cost / df['Date'].nunique())} MAD/j")
col4.metric("Articles Uniques ğŸ·ï¸", unique_articles)

# Interesting Fact ğŸ”
st.header("ğŸ” AperÃ§u IntÃ©ressant ğŸŒŸ")
if top_article is not None:
    st.info(
        f"Lâ€™article le plus coÃ»teux est **{sanitize_text(top_article['Article'])}** "
        f"avec un coÃ»t total de **{abbreviate_number(top_article['Montant'])} MAD**. ğŸ’°âœ¨"
    )
else:
    st.warning("Aucune donnÃ©e disponible pour lâ€™aperÃ§u intÃ©ressant. ğŸ˜¢")

# Export Data ğŸ’¾
st.header("ğŸ’¾ Exporter les DonnÃ©es ğŸ“¥")
st.download_button(
    label="TÃ©lÃ©charger les DonnÃ©es en CSV ğŸ“„",
    data=convert_df_to_csv(df_aggregated),
    file_name="donnees_consommation.csv",
    mime="text/csv",
)

# Visualizations ğŸ“ˆ
st.header("ğŸ“ˆ Visualisations ğŸ¨")
col1, col2 = st.columns(2)

with col1:
    st.subheader(f"Tendance de {trend_metric} au Fil du Temps ğŸ“…")
    st.markdown("Cette courbe montre lâ€™Ã©volution quotidienne de la consommation, avec une option de lissage. ğŸ“ˆ")
    fig_trend = px.line(
        viz_data['trend_data'],
        x='Date',
        y='Valeur',
        color='MÃ©trique',
        title=f"Tendance de {trend_metric} au Fil du Temps",
        labels={'Valeur': trend_metric},
        template='plotly_dark',
        hover_data={'Valeur': ':,.2f'}
    )
    if smoothing > 0:
        smoothed = viz_data['trend_data']['Valeur'].rolling(window=smoothing).mean()
        fig_trend.add_scatter(
            x=viz_data['trend_data']['Date'],
            y=smoothed,
            mode='lines',
            name='LissÃ©',
            line=dict(dash='dash', color='blue')
        )
    fig_trend.update_layout(font=dict(size=12), xaxis_tickangle=45)
    st.plotly_chart(fig_trend, use_container_width=True)

with col2:
    st.subheader(f"RÃ©partition des {cat_metric} par CatÃ©gorie ğŸ¥§")
    st.markdown("Ce graphique en donut montre la part de chaque catÃ©gorie dans la consommation totale. ğŸ¨")
    if not viz_data['cat_data'].empty and isinstance(viz_data['cat_data'], pd.DataFrame) and 'Desc_Cat' in viz_data['cat_data'].columns and 'Valeur' in viz_data['cat_data'].columns:
        fig_cat = px.pie(
            viz_data['cat_data'],
            names='Desc_Cat',
            values='Valeur',
            title=f"RÃ©partition des {cat_metric} par CatÃ©gorie",
            template='plotly_dark',
            color_discrete_sequence=px.colors.qualitative.Bold,
            hover_data={'Valeur': ':,.2f'}
        )
        fig_cat.update_traces(textinfo="percent+label")
        fig_cat.update_layout(font=dict(size=12))
        st.plotly_chart(fig_cat, use_container_width=True)
    else:
        st.warning("Aucune donnÃ©e disponible pour la rÃ©partition par catÃ©gorie. ğŸ˜¢âš ï¸")

with col1:
    st.subheader(f"Top 5 Articles par {art_metric} ğŸ†")
    st.markdown("Ce graphique prÃ©sente les articles les plus consommÃ©s par quantitÃ© ou coÃ»t. ğŸŒŸ")
    fig_top = px.bar(
        viz_data['top_articles'],
        x='Article',
        y='Valeur',
        title=f"Top 5 Articles par {art_metric}",
        labels={'Valeur': art_metric},
        template='plotly_dark',
        hover_data={'Valeur': ':,.2f'},
        text_auto=True
    )
    fig_top.update_layout(font=dict(size=12), xaxis_tickangle=45)
    st.plotly_chart(fig_top, use_container_width=True)

with col2:
    st.subheader("RÃ©partition des QuantitÃ©s par Organisation ğŸ“Š")
    st.markdown("Ce graphique en boÃ®te montre la variabilitÃ© des quantitÃ©s consommÃ©es par organisation. ğŸ“ˆ")
    fig_box = px.box(
        viz_data['box_data'],
        x='Org_Log',
        y='Qte',
        title="RÃ©partition des QuantitÃ©s par Organisation",
        template='plotly_dark',
        hover_data={'Qte': ':,.2f'}
    )
    fig_box.update_layout(font=dict(size=12), xaxis_tickangle=45, showlegend=False)
    st.plotly_chart(fig_box, use_container_width=True)

# Advanced Analyses ğŸ”
st.header("ğŸ” Analyses AvancÃ©es ğŸš€")
with st.expander("ğŸ“ˆ PrÃ©vision de la Consommation ğŸ”®"):
    st.markdown("PrÃ©vision de la consommation pour les 5 articles les plus consommÃ©s sur les 6 prochains mois. ğŸŒŸ")
    if not viz_data['forecast_data'].empty:
        fig_forecast = px.line(
            viz_data['forecast_data'],
            x='Index',
            y='QuantitÃ©',
            color='Article',
            line_dash='Type',
            title='PrÃ©vision de la Consommation pour les Top Articles',
            labels={'Index': 'PÃ©riode'},
            template='plotly_dark',
            hover_data={'QuantitÃ©': ':,.2f'}
        )
        fig_forecast.update_layout(font=dict(size=12), xaxis_tickangle=45)
        st.plotly_chart(fig_forecast, use_container_width=True)
        st.markdown("**Recommandations de stock :** ğŸ“¦")
        for rec in viz_data['forecast_recommendations']:
            st.markdown(f"- {rec}")
    else:
        st.warning("DonnÃ©es insuffisantes pour la prÃ©vision. âš ï¸ğŸ˜¢")

with st.expander("âš ï¸ DÃ©tection des Anomalies ğŸ•µï¸â€â™‚ï¸"):
    st.markdown("Identification des consommations inhabituelles par catÃ©gorie (scores Z > 3 ou < -3). ğŸ”")
    if not viz_data['anomaly_data'].empty:
        st.dataframe(viz_data['anomaly_data'], use_container_width=True)
    else:
        st.warning("Aucune anomalie dÃ©tectÃ©e. âœ…ğŸ‰")

# Data Table ğŸ“‹
st.header("ğŸ“‹ DonnÃ©es de Consommation ğŸ—‚ï¸")
items_per_page = 10
total_pages = (len(df_aggregated) + items_per_page - 1) // items_per_page
page = st.slider("Page ğŸ“„", 1, max(1, total_pages), 1)
start_idx = (page - 1) * items_per_page
end_idx = start_idx + items_per_page
paged_df = df_aggregated.iloc[start_idx:end_idx]
st.dataframe(
    paged_df[["Article", "Org_Log", "Desc_Cat", "Qte", "Montant", "unit_cost"]].style.format(
        {"Qte": "{:.2f}", "Montant": "{:.2f}", "unit_cost": "{:.2f}"}
    ),
    use_container_width=True
)
st.write(f"Page {page} sur {total_pages} ğŸ“–")

# Word Report Download ğŸ“¥
st.header("ğŸ“¥ TÃ©lÃ©chargement du Rapport ğŸ“")
word_buffer = generate_word_document(selected_org, selected_cat, date_range, viz_data, df, total_quantity, total_cost, unique_articles, top_article)
st.download_button(
    label="TÃ©lÃ©charger le Rapport en Word ğŸ“„âœ¨",
    data=word_buffer,
    file_name="rapport_consommation.docx",
    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
)